#!/usr/bin/env bash

#
# Copyright (C) 2019 Transaction Processing Performance Council (TPC) and/or its contributors.
# This file is part of a software package distributed by the TPC
# The contents of this file have been developed by the TPC, and/or have been licensed to the TPC under one or more contributor
# license agreements.
# This file is subject to the terms and conditions outlined in the End-User
# License Agreement (EULA) which can be found in this distribution (EULA.txt) and is available at the following URL:
# http://www.tpc.org/TPC_Documents_Current_Versions/txt/EULA.txt
# Unless required by applicable law or agreed to in writing, this software is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, and the user bears the entire risk as to quality
# and performance as well as the entire cost of service or repair in case of defect. See the EULA for more details.
# 
#


#
# Copyright 2015-2019 Intel Corporation.
# This software and the related documents are Intel copyrighted materials, and your use of them 
# is governed by the express license under which they were provided to you ("License"). Unless the 
# License provides otherwise, you may not use, modify, copy, publish, distribute, disclose or 
# transmit this software or the related documents without Intel's prior written permission.
# 
# This software and the related documents are provided as is, with no express or implied warranties, 
# other than those that are expressly stated in the License.
# 
#

# this is common function to all queries in this engine
query_explain_method () {
  QUERY_SCRIPT="${QUERY_DIR}/explain_${QUERY_NAME}.sql"
  if [ ! -r "$QUERY_SCRIPT" ]
  then
  echo "SQL file $QUERY_SCRIPT can not be read."
  exit 1
  fi

  runCmdWithErrorCheck runEngineCmd -f "$QUERY_SCRIPT"
  return $?
}

QUERY_RESOURCES="${BIG_BENCH_QUERY_RESOURCES}"

SPARK_ENGINE_DIR="$BIG_BENCH_ENGINE_DIR"

export BIG_BENCH_ENGINE_CONF_DIR="${SPARK_ENGINE_DIR}/conf"

export BIG_BENCH_ENGINE_BIN_DIR="${BIG_BENCH_ENGINE_DIR}/bin"
export BIG_BENCH_QUERIES_DIR="${BIG_BENCH_ENGINE_DIR}/queries"
export BIG_BENCH_CLEAN_DIR="${BIG_BENCH_ENGINE_DIR}/clean"
export BIG_BENCH_POPULATION_DIR="${BIG_BENCH_ENGINE_DIR}/population"
export BIG_BENCH_REFRESH_DIR="${BIG_BENCH_ENGINE_DIR}/refresh"

export BIG_BENCH_CLEAN_METASTORE_FILE="$BIG_BENCH_CLEAN_DIR/dropTables.sql"
export BIG_BENCH_POPULATE_METASTORE_FILE="${USER_POPULATE_FILE:-"$BIG_BENCH_POPULATION_DIR/sparkSqlCreateLoad.sql"}"
export BIG_BENCH_REFRESH_METASTORE_FILE="${USER_REFRESH_FILE:-"$BIG_BENCH_REFRESH_DIR/sparkSqlRefreshCreateLoad.sql"}"
export BIG_BENCH_QUERY_PARAMS_FILE="${BIG_BENCH_ENGINE_DIR}/conf/queryParameters.sql"
export BIG_BENCH_ENGINE_SETTINGS_FILE="${BIG_BENCH_ENGINE_CONF_DIR}/engineSettings.sql"

SPARK_SQL_BINARY="spark-sql"
SPARK_SUBMIT_BINARY="spark-submit"

SPARK_DEPLOY_MODE="client"
SPARK_MASTER="yarn"
SPARK_JARS="${QUERY_RESOURCES}/bigbench-ml-spark-2.3.jar"

# --driver-memory 4g is very conservative. you want to increase this
# make sure every resouce and file used within the queries is made known to spark via --jars and --files
BINARY_PARAMS=(--deploy-mode ${SPARK_DEPLOY_MODE} --master ${SPARK_MASTER} --jars ${SPARK_JARS})

#LOAD_STAGE file format
#choices are: TEXTFILE, RCFILE, ORC, SEQUENCEFILE, PARQUET, AVRO or: "INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname"
export BIG_BENCH_spark_sql_default_fileformat_source_table="ORC"

#Temporary Tables file format inside the queries.
#choices are:  TextFile, SequenceFile, RCfile, and ORC.
#"$BIG_BENCH_spark_sql_default_fileformat_tmp_table" is used to override "hive.default.fileformat"
#(PARQUET is NOT! supported here. This is a limitiation of hive, as hive.default.fileformat only accepts the listed options)
# => all "CREATE <TEMPORARY> TABLE" statements within the queries will use the specified fileformat during bigbench execution (except the "result" table)
export BIG_BENCH_spark_sql_default_fileformat_tmp_table="TEXTFILE"

#Query result table format
#do not modify "_result_table" file format! Final query result has to be kept human readable!
export BIG_BENCH_spark_sql_default_fileformat_result_table="TEXTFILE"

# specify the Spark version
# options are:
# - spark : for spark 2.0 to spark 2.2
# - spark-2.3 : for spark 2.3+
export BIG_BENCH_ENGINE_SPARK_SQL_ML_FRAMEWORK="spark-2.3"

#Binary and launch parameters for Spark used to execute the machine learning part of the queries.
#export BIG_BENCH_ENGINE_SPARK_SQL_ML_FRAMEWORK_SPARK_BINARY="spark-submit --deploy-mode cluster --master yarn"
export BIG_BENCH_ENGINE_SPARK_SQL_ML_FRAMEWORK_SPARK_BINARY="${SPARK_SUBMIT_BINARY} ${BINARY_PARAMS[@]}"

BINARY="${SPARK_SQL_BINARY}"

# this function is a wrapper for the default engine command (like "hive")
# it assures that the environment (e.g., binary parameters, init sql files) is properly set
runEngineCmd () {
  if addInitScriptsToParams
  then
    "$BINARY" "${BINARY_PARAMS[@]}" "${INIT_PARAMS[@]}" "$@"
  else
    return 1
  fi
}

# sets up the environment when a query is to be executed
initQueryEnv () {
  if [ -z "$QUERY_NUMBER" ]
  then
    echo "The query number must be set."
    return 1
  fi

  if [ $QUERY_NUMBER -lt 1 ]
  then
    echo "Query number must be greater than 0"
    return 1
  fi

  if [ $QUERY_NUMBER -lt 10 ]
  then
    QUERY_NAME=q0$QUERY_NUMBER
  else
    QUERY_NAME=q$QUERY_NUMBER
  fi

  QUERY_DIR="$BIG_BENCH_QUERIES_DIR/$QUERY_NAME"
  if [ ! -d "$QUERY_DIR" ]
  then
    echo "Query directory $QUERY_DIR does not exist"
    return 1
  fi

  VALIDATION_RESULTS_DIR="$QUERY_DIR/results"
  if [ ! -d "$VALIDATION_RESULTS_DIR" ]
  then
    echo "Validation results directory $VALIDATION_RESULTS_DIR does not exist"
  return 1
  fi
  VALIDATION_RESULTS_FILENAME="$VALIDATION_RESULTS_DIR/$QUERY_NAME-result"

  # QUERY_DIR is set earlier in this method.
  # Therefore LOCAL_QUERY_ENGINE_SETTINGS_FILE can only be set here and not outside in the global part
  LOCAL_QUERY_ENGINE_SETTINGS_FILE="$QUERY_DIR/engineLocalSettings.sql"
  # As this file has to be added to the INIT_PARAMS array, recall that function to update the array
  if ! addInitScriptsToParams
  then
    return 1
  fi

  TABLE_PREFIX="${QUERY_NAME}_${BIG_BENCH_ENGINE}_${BIG_BENCH_BENCHMARK_PHASE}_${BIG_BENCH_STREAM_NUMBER}"

  RESULT_TABLE="${TABLE_PREFIX}_result"
  RESULT_DIR="$BIG_BENCH_HDFS_ABSOLUTE_QUERY_RESULT_DIR/$RESULT_TABLE"
  TEMP_TABLE="${TABLE_PREFIX}_temp"
  TEMP_DIR="$BIG_BENCH_HDFS_ABSOLUTE_TEMP_DIR/$TEMP_TABLE"

  LOG_FILE_NAME="$BIG_BENCH_LOGS_DIR/${TABLE_PREFIX}.log"
  EXPLAIN_LOG_FILE_NAME="$BIG_BENCH_LOGS_DIR/explain_${TABLE_PREFIX}.log"


  LOCAL_QUERY_ENGINE_SETTINGS_CONF_FILE="$QUERY_DIR/engineLocalSettings.conf"
  if [ -s "$LOCAL_QUERY_ENGINE_SETTINGS_CONF_FILE" ]
  then
    source $LOCAL_QUERY_ENGINE_SETTINGS_CONF_FILE
  fi

  BINARY_PARAMS+=(--hiveconf BENCHMARK_PHASE=$BIG_BENCH_BENCHMARK_PHASE --hiveconf STREAM_NUMBER=$BIG_BENCH_STREAM_NUMBER --hiveconf QUERY_NAME=$QUERY_NAME --hiveconf QUERY_DIR=$QUERY_DIR --hiveconf RESULT_TABLE=$RESULT_TABLE --hiveconf RESULT_DIR=$RESULT_DIR --hiveconf TEMP_TABLE=$TEMP_TABLE --hiveconf TEMP_DIR=$TEMP_DIR --hiveconf TABLE_PREFIX=$TABLE_PREFIX)

  # source run.sh as late as possible to allow run.sh to use all above defined variables
  SCRIPT_FILENAME="$QUERY_DIR/run.sh"
  if [ -r "$SCRIPT_FILENAME" ]
  then
    source "$SCRIPT_FILENAME"
  else
    echo "File $SCRIPT_FILENAME containing main method not found, aborting script."
  return 1
  fi

  # check if the explain method was implemented
  QUERY_EXPLAIN_METHOD="query_explain_method"
  if ! declare -F "$QUERY_EXPLAIN_METHOD" > /dev/null 2>&1
  then
    echo "$QUERY_EXPLAIN_METHOD was not implemented, aborting script"
    return 1
  fi

  # check if the main method was implemented properly in the run.sh
  QUERY_MAIN_METHOD="query_run_main_method"
  if ! declare -F "$QUERY_MAIN_METHOD" > /dev/null 2>&1
  then
    echo "$QUERY_MAIN_METHOD was not implemented, aborting script"
  return 1
  fi

  # check if the clean method was implemented properly in the run.sh
  QUERY_CLEAN_METHOD="query_run_clean_method"
  if ! declare -F "$QUERY_CLEAN_METHOD" > /dev/null 2>&1
  then
    echo "$QUERY_CLEAN_METHOD was not implemented, aborting script"
  return 1
  fi

  # check if the validate method was implemented properly in the run.sh
  QUERY_VALIDATE_METHOD="query_run_validate_method"
  if ! declare -F "$QUERY_VALIDATE_METHOD" > /dev/null 2>&1
  then
    echo "$QUERY_VALIDATE_METHOD was not implemented, aborting script"
  return 1
  fi
  return 0
}

# checks for the various files with environment settings and adds them to an array
# suitable to be appended to the engine run command
addInitScriptsToParams () {
  INIT_PARAMS=(-i "$BIG_BENCH_QUERY_PARAMS_FILE" -i "$BIG_BENCH_ENGINE_SETTINGS_FILE")

  if [[ -n "$LOCAL_QUERY_ENGINE_SETTINGS_FILE" && -s "$LOCAL_QUERY_ENGINE_SETTINGS_FILE" ]]
  then
    echo "Additional local spark sql settings found. Adding $LOCAL_QUERY_ENGINE_SETTINGS_FILE to spark sql init."
    INIT_PARAMS+=(-i "$LOCAL_QUERY_ENGINE_SETTINGS_FILE")
  fi

  if [ -n "$USER_QUERY_PARAMS_FILE" ]
  then
    if [ -r "$USER_QUERY_PARAMS_FILE" ]
    then
      echo "User defined query parameter file found. Adding $USER_QUERY_PARAMS_FILE to spark sql init."
      INIT_PARAMS+=(-i "$USER_QUERY_PARAMS_FILE")
    else
      echo "User query parameter file $USER_QUERY_PARAMS_FILE can not be read."
      return 1
    fi
  fi

  if [ -n "$USER_ENGINE_SETTINGS_FILE" ]
  then
    if [ -r "$USER_ENGINE_SETTINGS_FILE" ]
    then
      echo "User defined engine settings file found. Adding $USER_ENGINE_SETTINGS_FILE to spark sql init."
      INIT_PARAMS+=(-i "$USER_ENGINE_SETTINGS_FILE")
    else
      echo "User spark sql settings file $USER_ENGINE_SETTINGS_FILE can not be read."
      return 1
    fi
  fi
  return 0
}
